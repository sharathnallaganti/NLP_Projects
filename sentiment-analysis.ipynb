{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ----------------------------\n# Sentiment Analysis Baseline\n# Using TF-IDF + Logistic Regression\n# Dataset: IMDB reviews (positive / negative)\n# ----------------------------\n\nimport os\nimport joblib   # for saving the trained model\nimport numpy as np\nfrom datasets import load_dataset   # Hugging Face datasets (loads IMDB automatically)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport argparse\n\n# ----------------------------\n# MAIN FUNCTION\n# ----------------------------\ndef main(args):\n    # 1. Load dataset (IMDB has 25k train + 25k test)\n    ds = load_dataset(\"imdb\")\n    train_texts = ds[\"train\"][\"text\"]   # list of reviews\n    train_labels = ds[\"train\"][\"label\"] # list of labels (0=negative, 1=positive)\n    test_texts  = ds[\"test\"][\"text\"]\n    test_labels = ds[\"test\"][\"label\"]\n\n    # 2. Optionally shrink training size (for quick tests in Colab)\n    if args.max_train_samples > 0:\n        train_texts = train_texts[:args.max_train_samples]\n        train_labels = train_labels[:args.max_train_samples]\n\n    # 3. Define a pipeline\n    #    (a) Convert raw text â†’ numeric features (TF-IDF)\n    #    (b) Train a Logistic Regression classifier\n    pipe = Pipeline([\n        (\"tfidf\", TfidfVectorizer(\n            max_features=args.max_features,   # only keep top-N most frequent words\n            ngram_range=(1,2),                # use unigrams + bigrams\n            lowercase=True,\n            stop_words=\"english\"              # ignore common words like \"the\", \"and\", etc.\n        )),\n        (\"clf\", LogisticRegression(\n            C=2.0,          # regularization strength (higher = less regularization)\n            max_iter=200,   # max number of training iterations\n            n_jobs=-1       # use all CPU cores\n        ))\n    ])\n\n    # 4. Train the pipeline\n    print(\"Training Logistic Regression model...\")\n    pipe.fit(train_texts, train_labels)\n\n    # 5. Evaluate on test set\n    preds = pipe.predict(test_texts)\n    acc = accuracy_score(test_labels, preds)\n    f1  = f1_score(test_labels, preds)\n\n    print(f\"\\nBaseline Accuracy: {acc:.4f}\")\n    print(f\"Baseline F1 Score: {f1:.4f}\")\n    print(\"\\nDetailed Report:\\n\")\n    print(classification_report(test_labels, preds, target_names=[\"negative\",\"positive\"]))\n\n    # 6. Save the model\n    os.makedirs(args.out_dir, exist_ok=True)\n    joblib.dump(pipe, os.path.join(args.out_dir, \"baseline_tfidf_logreg.joblib\"))\n    print(f\"\\nModel saved to {os.path.join(args.out_dir, 'baseline_tfidf_logreg.joblib')}\")\n\n\n# ----------------------------\n# ENTRY POINT\n# ----------------------------\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--out_dir\", type=str, default=\"artifacts_baseline\",\n                        help=\"Folder to save trained model\")\n    parser.add_argument(\"--max_features\", type=int, default=50000,\n                        help=\"Number of words/ngrams to keep for TF-IDF\")\n    parser.add_argument(\"--max_train_samples\", type=int, default=0,\n                        help=\"Use fewer samples for quick tests (0 = use all data)\")\n\n    #Use parse_known_args() to avoid Jupyter/Colab crash with extra -f arg\n    args, _ = parser.parse_known_args()\n\n    main(args)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-02T01:14:30.884813Z","iopub.execute_input":"2025-10-02T01:14:30.885207Z","iopub.status.idle":"2025-10-02T01:15:01.030279Z","shell.execute_reply.started":"2025-10-02T01:14:30.885182Z","shell.execute_reply":"2025-10-02T01:15:01.029598Z"}},"outputs":[{"name":"stdout","text":"Training Logistic Regression model...\n\nBaseline Accuracy: 0.8846\nBaseline F1 Score: 0.8844\n\nDetailed Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.88      0.89      0.88     12500\n    positive       0.89      0.88      0.88     12500\n\n    accuracy                           0.88     25000\n   macro avg       0.88      0.88      0.88     25000\nweighted avg       0.88      0.88      0.88     25000\n\n\nModel saved to artifacts_baseline/baseline_tfidf_logreg.joblib\n","output_type":"stream"}],"execution_count":6}]}