{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport joblib\nimport numpy as np\nfrom datasets import load_dataset\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom sklearn.model_selection import train_test_split\nimport argparse\n\ndef main(args):\n    # 1) Load dataset (IMDB: 'text', 'label' where 0=neg,1=pos)\n    ds = load_dataset(\"imdb\")\n    train_texts = ds[\"train\"][\"text\"]\n    train_labels = ds[\"train\"][\"label\"]\n    test_texts  = ds[\"test\"][\"text\"]\n    test_labels = ds[\"test\"][\"label\"]\n\n    # Optional: shrink training size for quick runs\n    if args.max_train_samples > 0:\n        train_texts = train_texts[:args.max_train_samples]\n        train_labels = train_labels[:args.max_train_samples]\n\n    # 2) Build pipeline (TF-IDF â†’ Logistic Regression)\n    pipe = Pipeline([\n        (\"tfidf\", TfidfVectorizer(\n            max_features=args.max_features,\n            ngram_range=(1,2),\n            lowercase=True,\n            stop_words=\"english\"\n        )),\n        (\"clf\", LogisticRegression(\n            C=2.0,\n            max_iter=200,\n            n_jobs=-1\n        ))\n    ])\n\n    # 3) Train\n    pipe.fit(train_texts, train_labels)\n\n    # 4) Evaluate\n    preds = pipe.predict(test_texts)\n    acc = accuracy_score(test_labels, preds)\n    f1  = f1_score(test_labels, preds)\n\n    print(f\"Baseline Accuracy: {acc:.4f}\")\n    print(f\"Baseline F1 (macro-ish for binary): {f1:.4f}\")\n    print(classification_report(test_labels, preds, target_names=[\"neg\",\"pos\"]))\n\n    # 5) Save\n    os.makedirs(args.out_dir, exist_ok=True)\n    joblib.dump(pipe, os.path.join(args.out_dir, \"baseline_tfidf_logreg.joblib\"))\n    print(f\"Saved model to {os.path.join(args.out_dir, 'baseline_tfidf_logreg.joblib')}\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--out_dir\", type=str, default=\"artifacts_baseline\")\n    parser.add_argument(\"--max_features\", type=int, default=50000)\n    parser.add_argument(\"--max_train_samples\", type=int, default=0, help=\"0 = full dataset\")\n    args = parser.parse_args()\n    main(args)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-02T00:43:11.112339Z","iopub.execute_input":"2025-10-02T00:43:11.112500Z","iopub.status.idle":"2025-10-02T00:43:15.192507Z","shell.execute_reply.started":"2025-10-02T00:43:11.112485Z","shell.execute_reply":"2025-10-02T00:43:15.191434Z"}},"outputs":[],"execution_count":null}]}