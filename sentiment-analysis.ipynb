{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport joblib\nimport numpy as np\nfrom datasets import load_dataset\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom sklearn.model_selection import train_test_split\nimport argparse\n\ndef main(args):\n    # 1) Load dataset (IMDB: 'text', 'label' where 0=neg,1=pos)\n    ds = load_dataset(\"imdb\")\n    train_texts = ds[\"train\"][\"text\"]\n    train_labels = ds[\"train\"][\"label\"]\n    test_texts  = ds[\"test\"][\"text\"]\n    test_labels = ds[\"test\"][\"label\"]\n\n    # Optional: shrink training size for quick runs\n    if args.max_train_samples > 0:\n        train_texts = train_texts[:args.max_train_samples]\n        train_labels = train_labels[:args.max_train_samples]\n\n    # 2) Build pipeline (TF-IDF → Logistic Regression)\n    pipe = Pipeline([\n        (\"tfidf\", TfidfVectorizer(\n            max_features=args.max_features,\n            ngram_range=(1,2),\n            lowercase=True,\n            stop_words=\"english\"\n        )),\n        (\"clf\", LogisticRegression(\n            C=2.0,\n            max_iter=200,\n            n_jobs=-1\n        ))\n    ])\n\n    # 3) Train\n    pipe.fit(train_texts, train_labels)\n\n    # 4) Evaluate\n    preds = pipe.predict(test_texts)\n    acc = accuracy_score(test_labels, preds)\n    f1  = f1_score(test_labels, preds)\n\n    print(f\"Baseline Accuracy: {acc:.4f}\")\n    print(f\"Baseline F1 (macro-ish for binary): {f1:.4f}\")\n    print(classification_report(test_labels, preds, target_names=[\"neg\",\"pos\"]))\n\n    # 5) Save\n    os.makedirs(args.out_dir, exist_ok=True)\n    joblib.dump(pipe, os.path.join(args.out_dir, \"baseline_tfidf_logreg.joblib\"))\n    print(f\"Saved model to {os.path.join(args.out_dir, 'baseline_tfidf_logreg.joblib')}\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--out_dir\", type=str, default=\"artifacts_baseline\")\n    parser.add_argument(\"--max_features\", type=int, default=50000)\n    parser.add_argument(\"--max_train_samples\", type=int, default=0, help=\"0 = full dataset\")\n    args, _ = parser.parse_known_args()\n    main(args)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-02T01:10:03.381385Z","iopub.execute_input":"2025-10-02T01:10:03.382274Z","iopub.status.idle":"2025-10-02T01:10:44.162952Z","shell.execute_reply.started":"2025-10-02T01:10:03.382247Z","shell.execute_reply":"2025-10-02T01:10:44.162099Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b06b6f2a833c4a4ca11870eb83448bb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc4a9553294c457f91a16831714377e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d09f65dce12e49218fa42a4fafdb5193"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffaa23cd1055497cbbd13f92c4add463"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d31598ee249412d9b588cc708da04d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6f2d56c11aa41e6b13af02e1d1cbce9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea4264b3576a44068dfe4021f928be9a"}},"metadata":{}},{"name":"stdout","text":"Baseline Accuracy: 0.8846\nBaseline F1 (macro-ish for binary): 0.8844\n              precision    recall  f1-score   support\n\n         neg       0.88      0.89      0.88     12500\n         pos       0.89      0.88      0.88     12500\n\n    accuracy                           0.88     25000\n   macro avg       0.88      0.88      0.88     25000\nweighted avg       0.88      0.88      0.88     25000\n\nSaved model to artifacts_baseline/baseline_tfidf_logreg.joblib\n","output_type":"stream"}],"execution_count":3}]}